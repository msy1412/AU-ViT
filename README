# AU-Aware Vision Transformers for Biased Facial Expression Recognition
we propose a simple yet conceptually-new framework, AU-aware Vision Transformer (AU-ViT). It improves the performance of individual datasets by jointly training auxiliary datasets with AU or pseudo-AU labels. We also find that the AU-ViT is robust to real-world occlusions. Moreover, for the first time, we prove that a carefully-initialized ViT achieves comparable performance to advanced deep convolutional networks. Our AU-ViT achieves state-of-the-art performance on three popular datasets, namely 91.10% on RAF-DB, 65.59% on AffectNet, and 90.15% on FERPlus. The pretrained weights will be released soon.
# AU-ViT
:star: **train scripts**

```sh
python RAFDB_AU-ViT.py
python AffectNet_AU-ViT.py
python FERPlus_AU-ViT.py
```

# Citation

Do not forget to cite our work appropriately. 
```
@article{mao2022aware,
  title={AU-Aware Vision Transformers for Biased Facial Expression Recognition},
  author={Mao, Shuyi and Li, Xinpeng and Wu, Qingyang and Peng, Xiaojiang},
  journal={arXiv preprint arXiv:2211.06609},
  year={2022}
}
```